{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Simple Spark operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook requires a local installation of [Apache Spark](https://spark.apache.org/) (version 1.2 was used here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load a text file and count the lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of sample text files (from Project Gutenberg http://www.gutenberg.org/) in the /data directory in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample data files (you could use any text file)\n",
    "shakespeare = \"./data/shakespeare-works.txt\"\n",
    "aurelius = \"./data/marcus-aurelius-meditations.txt\"\n",
    "\n",
    "# Load one of these files\n",
    "fileName = shakespeare\n",
    "\n",
    "textFile = sc.textFile(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Count the lines in the file. \n",
    "* NB: This action will also force the RDD to materialise the data i.e. Spark will read the file at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x107296a10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./data/shakespeare-works.txt contains 122395 lines\n"
     ]
    }
   ],
   "source": [
    "print(\"File {0} contains {1} lines\".format(fileName, textFile.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Takes the length of each line in the file and find the maximum line length.\n",
    "* Again, this action forces Spark to read the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(textFile.map(lambda s: len(s)).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum line length is 85\n"
     ]
    }
   ],
   "source": [
    "maxlen = textFile.map(lambda s: len(s)).max()\n",
    "print(\"Maximum line length is {0}\".format(maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Create a simple Python function to count words in a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will use these functions when we process the Spark RDDs below.\n",
    "* The `extract_words()` function is pretty basic and we could probably refine this with a better regex, making it case-insensitive etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import regular expression library\n",
    "import re\n",
    "\n",
    "def extract_words(s):\n",
    "    \"\"\"Split input string into words using RE\"\"\"\n",
    "    return re.split('\\W+', s)\n",
    "\n",
    "def count_words(s):\n",
    "    \"\"\"Split input string into words using RE and return count\"\"\"\n",
    "    words = extract_words(s)\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the count_words function with a simple string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String 'why hello there, Old old chap' contains 6 words\n"
     ]
    }
   ],
   "source": [
    "s = \"why hello there, Old old chap\"\n",
    "print(\"String '{0}' contains {1} words\".format(s, count_words(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Use your custom Python function with your Spark RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this custom function in the standard RDD map() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1609',\n",
       " u'',\n",
       " u'THE SONNETS',\n",
       " u'',\n",
       " u'by William Shakespeare',\n",
       " u'',\n",
       " u'',\n",
       " u'',\n",
       " u'                     1',\n",
       " u'  From fairest creatures we desire increase,',\n",
       " u\"  That thereby beauty's rose might never die,\",\n",
       " u'  But as the riper should by time decease,',\n",
       " u'  His tender heir might bear his memory:',\n",
       " u'  But thou contracted to thine own bright eyes,',\n",
       " u\"  Feed'st thy light's flame with self-substantial fuel,\",\n",
       " u'  Making a famine where abundance lies,',\n",
       " u'  Thy self thy foe, to thy sweet self too cruel:',\n",
       " u\"  Thou that art now the world's fresh ornament,\",\n",
       " u'  And only herald to the gaudy spring,',\n",
       " u'  Within thine own bud buriest thy content,',\n",
       " u\"  And tender churl mak'st waste in niggarding:\",\n",
       " u'    Pity the world, or else this glutton be,',\n",
       " u\"    To eat the world's due, by the grave and thee.\",\n",
       " u'',\n",
       " u'',\n",
       " u'                     2',\n",
       " u'  When forty winters shall besiege thy brow,',\n",
       " u\"  And dig deep trenches in thy beauty's field,\",\n",
       " u\"  Thy youth's proud livery so gazed on now,\",\n",
       " u'  Will be a tattered weed of small worth held:',\n",
       " u'  Then being asked, where all thy beauty lies,',\n",
       " u'  Where all the treasure of thy lusty days;',\n",
       " u'  To say within thine own deep sunken eyes,',\n",
       " u'  Were an all-eating shame, and thriftless praise.',\n",
       " u\"  How much more praise deserved thy beauty's use,\",\n",
       " u\"  If thou couldst answer 'This fair child of mine\",\n",
       " u\"  Shall sum my count, and make my old excuse'\",\n",
       " u'  Proving his beauty by succession thine.',\n",
       " u'    This were to be new made when thou art old,',\n",
       " u\"    And see thy blood warm when thou feel'st it cold.\",\n",
       " u'',\n",
       " u'',\n",
       " u'                     3',\n",
       " u'  Look in thy glass and tell the face thou viewest,',\n",
       " u'  Now is the time that face should form another,',\n",
       " u'  Whose fresh repair if now thou not renewest,',\n",
       " u'  Thou dost beguile the world, unbless some mother.',\n",
       " u'  For where is she so fair whose uneared womb',\n",
       " u'  Disdains the tillage of thy husbandry?',\n",
       " u'  Or who is he so fond will be the tomb,',\n",
       " u'  Of his self-love to stop posterity?',\n",
       " u\"  Thou art thy mother's glass and she in thee\",\n",
       " u'  Calls back the lovely April of her prime,',\n",
       " u'  So thou through windows of thine age shalt see,',\n",
       " u'  Despite of wrinkles this thy golden time.',\n",
       " u'    But if thou live remembered not to be,',\n",
       " u'    Die single and thine image dies with thee.',\n",
       " u'',\n",
       " u'',\n",
       " u'                     4',\n",
       " u'  Unthrifty loveliness why dost thou spend,',\n",
       " u\"  Upon thy self thy beauty's legacy?\",\n",
       " u\"  Nature's bequest gives nothing but doth lend,\",\n",
       " u'  And being frank she lends to those are free:',\n",
       " u'  Then beauteous niggard why dost thou abuse,',\n",
       " u'  The bounteous largess given thee to give?',\n",
       " u'  Profitless usurer why dost thou use',\n",
       " u'  So great a sum of sums yet canst not live?',\n",
       " u'  For having traffic with thy self alone,',\n",
       " u'  Thou of thy self thy sweet self dost deceive,',\n",
       " u'  Then how when nature calls thee to be gone,',\n",
       " u'  What acceptable audit canst thou leave?',\n",
       " u'    Thy unused beauty must be tombed with thee,',\n",
       " u\"    Which used lives th' executor to be.\",\n",
       " u'',\n",
       " u'',\n",
       " u'                     5',\n",
       " u'  Those hours that with gentle work did frame',\n",
       " u'  The lovely gaze where every eye doth dwell',\n",
       " u'  Will play the tyrants to the very same,',\n",
       " u'  And that unfair which fairly doth excel:',\n",
       " u'  For never-resting time leads summer on',\n",
       " u'  To hideous winter and confounds him there,',\n",
       " u'  Sap checked with frost and lusty leaves quite gone,',\n",
       " u\"  Beauty o'er-snowed and bareness every where:\",\n",
       " u\"  Then were not summer's distillation left\",\n",
       " u'  A liquid prisoner pent in walls of glass,',\n",
       " u\"  Beauty's effect with beauty were bereft,\",\n",
       " u'  Nor it nor no remembrance what it was.',\n",
       " u'    But flowers distilled though they with winter meet,',\n",
       " u'    Leese but their show, their substance still lives sweet.',\n",
       " u'',\n",
       " u'',\n",
       " u'                     6',\n",
       " u\"  Then let not winter's ragged hand deface,\",\n",
       " u'  In thee thy summer ere thou be distilled:',\n",
       " u'  Make sweet some vial; treasure thou some place,',\n",
       " u\"  With beauty's treasure ere it be self-killed:\",\n",
       " u'  That use is not forbidden usury,',\n",
       " u'  Which happies those that pay the willing loan;']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordsPerLine = textFile.map(lambda s: count_words(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of words in a line is: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum number of words in a line is: {0}\".format(wordsPerLine.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Do some classic word-count stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each line in the text file is read and converted into a list of words.\n",
    "* The word-lists for the separate lines are then *flattened* into a single list of words.\n",
    "* We then do the classic word-count **`map`** operation i.e. spit out a pair of (word, 1) for each word in the list.\n",
    "* Now we **`reduce`** the list of (word, 1) tuples, grouping them by the key (word), and adding up all the 1's for each word.\n",
    "* This gives as a **tuple of (word, count)** for each distinct word in the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1609',\n",
       " u'',\n",
       " u'the',\n",
       " u'sonnets',\n",
       " u'',\n",
       " u'by',\n",
       " u'william',\n",
       " u'shakespeare',\n",
       " u'',\n",
       " u'']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.flatMap(lambda line: extract_words(line.lower())).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate word counts as another RDD\n",
    "\n",
    "countsRDD = (textFile.flatMap(lambda line: extract_words(line.lower()))\n",
    "            .filter(lambda word: len(word)>0)\n",
    "            .map(lambda word: (word, 1))\n",
    "            .reduceByKey(lambda a, b: a+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We might choose to cache this RDD in Spark, so that we can re-use the RDD in different places later on without having to re-generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[28] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countsRDD.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Find N most common words in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Spark likes working with [key-value pairs](http://spark.apache.org/docs/1.2.0/programming-guide.html#working-with-key-value-pairs) and our tuples are (key, value) pairs of **(word, count)**, i.e. the key is **word**.\n",
    "* But we now want to sort them in order of **count** to get the most/least common words.\n",
    "* The easy way to do this is to flip the tuples around as (count, word), then sort them by their key (count).\n",
    "* Then we just `take` the required number of items off the sorted list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find N most common words by count\n",
    "n = 10\n",
    "mostcommon = countsRDD \\\n",
    "           .map(lambda (w,c):(c,w)) \\\n",
    "           .sortByKey(ascending=False) \\\n",
    "           .take(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common 10 words\n",
      "====================\n",
      "the : 27378\n",
      "and : 26084\n",
      "i : 22538\n",
      "to : 19771\n",
      "of : 17481\n",
      "a : 14725\n",
      "you : 13826\n",
      "my : 12490\n",
      "that : 11318\n",
      "in : 11112\n"
     ]
    }
   ],
   "source": [
    "print(\"Most common {0} words\\n====================\".format(n))\n",
    "for (c, w) in mostcommon:\n",
    "    print(\"{0} : {1}\".format(w, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Find N least common words in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Same principle as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find N least common words by count\n",
    "n = 10\n",
    "leastcommon = countsRDD \\\n",
    "           .map(lambda (w,c):(c,w)) \\\n",
    "           .sortByKey(ascending=True) \\\n",
    "           .take(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least common 10 words\n",
      "=====================\n",
      "aided : 1\n",
      "gag : 1\n",
      "cxsar : 1\n",
      "pretended : 1\n",
      "conjuring : 1\n",
      "offendeth : 1\n",
      "reposeth : 1\n",
      "rupture : 1\n",
      "swoopstake : 1\n",
      "digit : 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Least common {0} words\\n=====================\".format(n))\n",
    "for (c, w) in leastcommon:\n",
    "    print(\"{0} : {1}\".format(w, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[10] at RDD at PythonRDD.scala:42"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Release the cache:\n",
    "countsRDD.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#*That's all, folks!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
